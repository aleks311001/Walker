{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c420b718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T09:16:23.820180Z",
     "start_time": "2022-07-16T09:16:23.236966Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set(font_scale=1.3, style='darkgrid', palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4690a7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T09:16:24.553825Z",
     "start_time": "2022-07-16T09:16:23.863042Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "\n",
    "import brian2 as b2\n",
    "import gym\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import Walker750\n",
    "from Walker750 import Side, Joint\n",
    "\n",
    "import warnings\n",
    "from warnings import filterwarnings\n",
    "# filterwarnings(action='ignore')\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, module='.*brian2.*')\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, \n",
    "               message='.*the imp module is deprecated in favour of importlib and slated for.*')\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, \n",
    "               message='.*WARN: Initializing wrapper in old step API which returns one bool instead.*')\n",
    "filterwarnings(action='ignore', category=DeprecationWarning,\n",
    "               message='.*WARN: Initializing environment in old step API which returns one bool.*')\n",
    "filterwarnings(action='ignore', category=UserWarning, \n",
    "               message='.*WARN: We recommend you to use a symmetric and normalized Box action space.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249931e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:11:21.389925Z",
     "start_time": "2022-07-16T05:52:38.575980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9361926ebf1c4e28bd7d17041df661a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 4.04114\n",
      "params = [38.20107157  3.70866354]; convergence = 0.027106401069517685\n",
      "\n",
      "differential_evolution step 2: f(x)= 4.04114\n",
      "params = [38.20107157  3.70866354]; convergence = 0.02124988160697081\n",
      "\n",
      "differential_evolution step 3: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.016439074800481374\n",
      "\n",
      "differential_evolution step 4: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.016488974177780835\n",
      "\n",
      "differential_evolution step 5: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.016519707293346494\n",
      "\n",
      "differential_evolution step 6: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.015337401291705317\n",
      "\n",
      "differential_evolution step 7: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.013867419972365935\n",
      "\n",
      "differential_evolution step 8: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.010685207174919688\n",
      "\n",
      "differential_evolution step 9: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.00949337392318482\n",
      "\n",
      "differential_evolution step 10: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.00869388776244041\n",
      "\n",
      "differential_evolution step 11: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.007090731225813839\n",
      "\n",
      "differential_evolution step 12: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.007090731225813839\n",
      "\n",
      "differential_evolution step 13: f(x)= -5.21135\n",
      "params = [34.45583122  3.17358153]; convergence = 0.006337858863472052\n",
      "\n",
      "differential_evolution step 14: f(x)= -5.97453\n",
      "params = [34.45963303  3.30402514]; convergence = 0.005257408400772602\n",
      "\n",
      "differential_evolution step 15: f(x)= -5.97453\n",
      "params = [34.45963303  3.30402514]; convergence = 0.005022770480660562\n",
      "\n",
      "differential_evolution step 16: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.004728165481994697\n",
      "\n",
      "differential_evolution step 17: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.003131263775592542\n",
      "\n",
      "differential_evolution step 18: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.0028584204460875653\n",
      "\n",
      "differential_evolution step 19: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.002057118744204887\n",
      "\n",
      "differential_evolution step 20: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.001698140969449404\n",
      "\n",
      "differential_evolution step 21: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.001698140969449404\n",
      "\n",
      "differential_evolution step 22: f(x)= -7.02232\n",
      "params = [37.15636043  3.66952487]; convergence = 0.001343556650903886\n",
      "\n",
      "differential_evolution step 23: f(x)= -7.86833\n",
      "params = [36.44681611  2.18896362]; convergence = 0.006290325263373809\n",
      "\n",
      "differential_evolution step 24: f(x)= -7.86833\n",
      "params = [36.44681611  2.18896362]; convergence = 0.0073355002893620985\n",
      "\n",
      "differential_evolution step 25: f(x)= -7.86833\n",
      "params = [36.44681611  2.18896362]; convergence = 0.007659588955032483\n",
      "\n",
      "differential_evolution step 26: f(x)= -7.86833\n",
      "params = [36.44681611  2.18896362]; convergence = 0.007659588955032483\n",
      "\n",
      "differential_evolution step 27: f(x)= -9.02797\n",
      "params = [33.70535109  2.0820582 ]; convergence = 0.007941425690275566\n",
      "\n",
      "differential_evolution step 28: f(x)= -9.02797\n",
      "params = [33.70535109  2.0820582 ]; convergence = 0.008666738860388911\n",
      "\n",
      "differential_evolution step 29: f(x)= -9.02797\n",
      "params = [33.70535109  2.0820582 ]; convergence = 0.009141807428755663\n",
      "\n",
      "differential_evolution step 30: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.012633025638740022\n",
      "\n",
      "differential_evolution step 31: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.012625400449478809\n",
      "\n",
      "differential_evolution step 32: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013259910751982148\n",
      "\n",
      "differential_evolution step 33: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013262566560160262\n",
      "\n",
      "differential_evolution step 34: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013262566560160262\n",
      "\n",
      "differential_evolution step 35: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013262566560160262\n",
      "\n",
      "differential_evolution step 36: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.01326292286159118\n",
      "\n",
      "differential_evolution step 37: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.01326292286159118\n",
      "\n",
      "differential_evolution step 38: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013428642660093342\n",
      "\n",
      "differential_evolution step 39: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013428642660093342\n",
      "\n",
      "differential_evolution step 40: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013494469811501028\n",
      "\n",
      "differential_evolution step 41: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.013494469811501028\n",
      "\n",
      "differential_evolution step 42: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.018626534968221666\n",
      "\n",
      "differential_evolution step 43: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.018819876518936646\n",
      "\n",
      "differential_evolution step 44: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.01882682373699316\n",
      "\n",
      "differential_evolution step 45: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.019902066479368038\n",
      "\n",
      "differential_evolution step 46: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.019902066479368038\n",
      "\n",
      "differential_evolution step 47: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.020220548942125237\n",
      "\n",
      "differential_evolution step 48: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.02156594258133604\n",
      "\n",
      "differential_evolution step 49: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.02410229515718226\n",
      "\n",
      "differential_evolution step 50: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024154458593442393\n",
      "\n",
      "differential_evolution step 51: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024153634768764313\n",
      "\n",
      "differential_evolution step 52: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024153634768764313\n",
      "\n",
      "differential_evolution step 53: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024153634768764313\n",
      "\n",
      "differential_evolution step 54: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024153634768764313\n",
      "\n",
      "differential_evolution step 55: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.024153634768764313\n",
      "\n",
      "differential_evolution step 56: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.02508758863528003\n",
      "\n",
      "differential_evolution step 57: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.02595500358895441\n",
      "\n",
      "differential_evolution step 58: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.026108378063625252\n",
      "\n",
      "differential_evolution step 59: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.026108378063625252\n",
      "\n",
      "differential_evolution step 60: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.026108378063625252\n",
      "\n",
      "differential_evolution step 61: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.03989768606147073\n",
      "\n",
      "differential_evolution step 62: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.03989768606147073\n",
      "\n",
      "differential_evolution step 63: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.040946318491237005\n",
      "\n",
      "differential_evolution step 64: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04136003157192249\n",
      "\n",
      "differential_evolution step 65: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 66: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 67: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 68: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 69: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 70: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 71: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 72: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04261325054253155\n",
      "\n",
      "differential_evolution step 73: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04266194707213124\n",
      "\n",
      "differential_evolution step 74: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04330658615059641\n",
      "\n",
      "differential_evolution step 75: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04330658615059641\n",
      "\n",
      "differential_evolution step 76: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04526516611671568\n",
      "\n",
      "differential_evolution step 77: f(x)= -9.38411\n",
      "params = [33.70727453  2.14805337]; convergence = 0.04541702319803668\n",
      "\n",
      "differential_evolution step 78: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04342559915148926\n",
      "\n",
      "differential_evolution step 79: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04608384588517938\n",
      "\n",
      "differential_evolution step 80: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04608384588517938\n",
      "\n",
      "differential_evolution step 81: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04608384588517938\n",
      "\n",
      "differential_evolution step 82: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04521987208078499\n",
      "\n",
      "differential_evolution step 83: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04538139272299393\n",
      "\n",
      "differential_evolution step 84: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04538139272299393\n",
      "\n",
      "differential_evolution step 85: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.045450585554306276\n",
      "\n",
      "differential_evolution step 86: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04432267247433157\n",
      "\n",
      "differential_evolution step 87: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04500060852880062\n",
      "\n",
      "differential_evolution step 88: f(x)= -9.84772\n",
      "params = [37.28859632  2.18823656]; convergence = 0.04422656518896204\n",
      "\n",
      "differential_evolution step 89: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04224519483969779\n",
      "\n",
      "differential_evolution step 90: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04215031674484594\n",
      "\n",
      "differential_evolution step 91: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04269147625719055\n",
      "\n",
      "differential_evolution step 92: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04269147625719055\n",
      "\n",
      "differential_evolution step 93: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04226083700847072\n",
      "\n",
      "differential_evolution step 94: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04139389530868434\n",
      "\n",
      "differential_evolution step 95: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04139389530868434\n",
      "\n",
      "differential_evolution step 96: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04139389530868434\n",
      "\n",
      "differential_evolution step 97: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04124042554766791\n",
      "\n",
      "differential_evolution step 98: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04124042554766791\n",
      "\n",
      "differential_evolution step 99: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.04124042554766791\n",
      "\n",
      "differential_evolution step 100: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.041349775948928136\n",
      "\n",
      "differential_evolution step 101: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05209434696848956\n",
      "\n",
      "differential_evolution step 102: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05209434696848956\n",
      "\n",
      "differential_evolution step 103: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05209434696848956\n",
      "\n",
      "differential_evolution step 104: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05373592412512496\n",
      "\n",
      "differential_evolution step 105: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05373592412512496\n",
      "\n",
      "differential_evolution step 106: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05373592412512496\n",
      "\n",
      "differential_evolution step 107: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05459166378664138\n",
      "\n",
      "differential_evolution step 108: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05459166378664138\n",
      "\n",
      "differential_evolution step 109: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05459166378664138\n",
      "\n",
      "differential_evolution step 110: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05459166378664138\n",
      "\n",
      "differential_evolution step 111: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05837759683682418\n",
      "\n",
      "differential_evolution step 112: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05837759683682418\n",
      "\n",
      "differential_evolution step 113: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.05837759683682418\n",
      "\n",
      "differential_evolution step 114: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06039407467577508\n",
      "\n",
      "differential_evolution step 115: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06039407467577508\n",
      "\n",
      "differential_evolution step 116: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06039407467577508\n",
      "\n",
      "differential_evolution step 117: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06039407467577508\n",
      "\n",
      "differential_evolution step 118: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06042396808019908\n",
      "\n",
      "differential_evolution step 119: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06035359958731812\n",
      "\n",
      "differential_evolution step 120: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06035359958731812\n",
      "\n",
      "differential_evolution step 121: f(x)= -10.3756\n",
      "params = [36.5335856   2.23219068]; convergence = 0.06110872458411631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-9:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; convergence = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvergence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWalker750\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:329\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    317\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    318\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                  constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[1;32m    328\u001b[0m                                  x0\u001b[38;5;241m=\u001b[39mx0) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:852\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 852\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:1209\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m trial_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_population_members, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# only calculate for feasible entries\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m trial_energies[feasible] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_population_energies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeasible\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# which solutions are 'improved'?\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m loc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accept_trial(\u001b[38;5;241m*\u001b[39mval) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m        \u001b[38;5;28mzip\u001b[39m(trial_energies, feasible, cv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_energies,\n\u001b[1;32m   1215\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeasible, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_violation)]\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:968\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver._calculate_population_energies\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m    966\u001b[0m parameters_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_parameters(population)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnfevs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    970\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(calc_energies)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# wrong number of arguments for _mapwrapper\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# or wrong length returned from the mapper\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/_lib/_util.py:477\u001b[0m, in \u001b[0;36mMapWrapper.__call__\u001b[0;34m(self, func, iterable)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# only accept one iterable because that's all Pool.map accepts\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;66;03m# wrong number of arguments\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe map-like callable must be of the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m form f(func, iterable)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# params0 = [1]        # u0, b, w, k_action\n",
    "\n",
    "bounds = [(0.9, 40), (0.3, 8)]\n",
    "#                    k_action\n",
    "\n",
    "n_iter = 200\n",
    "pbar = tqdm(total=n_iter)\n",
    "\n",
    "def callback(x, convergence):\n",
    "    print(f'params = {x}; convergence = {convergence}\\n')\n",
    "    with open('params.log', 'a') as f:\n",
    "        f.write(f'params = {x}; convergence = {convergence}\\n')\n",
    "    pbar.update(1)\n",
    "\n",
    "res = differential_evolution(Walker750.calc_reward, bounds, maxiter=n_iter, callback=callback,\n",
    "                             disp=True, updating='deferred', workers=9)\n",
    "pbar.close()\n",
    "\n",
    "# 16 - 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673382d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T09:15:18.688065Z",
     "start_time": "2022-07-16T07:20:34.478641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da72331ac354f1aba46b27a59c45cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.022317738312488296\n",
      "\n",
      "differential_evolution step 2: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.01978655351319585\n",
      "\n",
      "differential_evolution step 3: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.016235171162579946\n",
      "\n",
      "differential_evolution step 4: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.01518650373529712\n",
      "\n",
      "differential_evolution step 5: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.014392034310722944\n",
      "\n",
      "differential_evolution step 6: f(x)= -2.56061\n",
      "params = [38.72367091  0.96185765  0.19107554  0.64834897  3.30391761]; convergence = 0.01279714417457327\n",
      "\n",
      "differential_evolution step 7: f(x)= -3.06751\n",
      "params = [35.55708205  1.10822264  0.07123905  0.57747402  3.53415613]; convergence = 0.011614220729768377\n",
      "\n",
      "differential_evolution step 8: f(x)= -3.06751\n",
      "params = [35.55708205  1.10822264  0.07123905  0.57747402  3.53415613]; convergence = 0.01126866939554488\n",
      "\n",
      "differential_evolution step 9: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.011082002492075702\n",
      "\n",
      "differential_evolution step 10: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.01011994922135341\n",
      "\n",
      "differential_evolution step 11: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.009644945675308852\n",
      "\n",
      "differential_evolution step 12: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.008710850585742494\n",
      "\n",
      "differential_evolution step 13: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.008321365698400513\n",
      "\n",
      "differential_evolution step 14: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.008221550955139727\n",
      "\n",
      "differential_evolution step 15: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.007624961913847378\n",
      "\n",
      "differential_evolution step 16: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.007624874834909003\n",
      "\n",
      "differential_evolution step 17: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.007213431098878578\n",
      "\n",
      "differential_evolution step 18: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.006971140008354843\n",
      "\n",
      "differential_evolution step 19: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.006613551722866216\n",
      "\n",
      "differential_evolution step 20: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.006538973781222797\n",
      "\n",
      "differential_evolution step 21: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.006276886533946698\n",
      "\n",
      "differential_evolution step 22: f(x)= -6.15606\n",
      "params = [29.60921745  1.27486804  0.12507782  0.63463646  2.48301061]; convergence = 0.005704716073082031\n",
      "\n",
      "differential_evolution step 23: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.005607613503760152\n",
      "\n",
      "differential_evolution step 24: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.00541705931313672\n",
      "\n",
      "differential_evolution step 25: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.005196880402228117\n",
      "\n",
      "differential_evolution step 26: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.005029143929868882\n",
      "\n",
      "differential_evolution step 27: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.004896552316660041\n",
      "\n",
      "differential_evolution step 28: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.004803702161238828\n",
      "\n",
      "differential_evolution step 29: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.004772912855506155\n",
      "\n",
      "differential_evolution step 30: f(x)= -6.97281\n",
      "params = [39.3047127   1.17269974  0.11917262  0.52622396  3.06158049]; convergence = 0.004772912855506155\n",
      "\n",
      "differential_evolution step 31: f(x)= -8.5658\n",
      "params = [39.38101982  1.09796793  0.11534881  0.77653714  3.20612437]; convergence = 0.004392942663101214\n",
      "\n",
      "differential_evolution step 32: f(x)= -8.5658\n",
      "params = [39.38101982  1.09796793  0.11534881  0.77653714  3.20612437]; convergence = 0.004119461313301967\n",
      "\n",
      "differential_evolution step 33: f(x)= -8.5658\n",
      "params = [39.38101982  1.09796793  0.11534881  0.77653714  3.20612437]; convergence = 0.0037167888177961897\n",
      "\n",
      "differential_evolution step 34: f(x)= -8.5658\n",
      "params = [39.38101982  1.09796793  0.11534881  0.77653714  3.20612437]; convergence = 0.0034872496535485334\n",
      "\n",
      "differential_evolution step 35: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0032660011208742656\n",
      "\n",
      "differential_evolution step 36: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.003266021439129245\n",
      "\n",
      "differential_evolution step 37: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00308100543787556\n",
      "\n",
      "differential_evolution step 38: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0029960698057434677\n",
      "\n",
      "differential_evolution step 39: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0026810091064522405\n",
      "\n",
      "differential_evolution step 40: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.002497131302405891\n",
      "\n",
      "differential_evolution step 41: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.002497131302405891\n",
      "\n",
      "differential_evolution step 42: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00247055270826671\n",
      "\n",
      "differential_evolution step 43: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.002437418975819741\n",
      "\n",
      "differential_evolution step 44: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0024317571289930603\n",
      "\n",
      "differential_evolution step 45: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0024049094330105317\n",
      "\n",
      "differential_evolution step 46: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0022180572381176747\n",
      "\n",
      "differential_evolution step 47: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0022028603991010335\n",
      "\n",
      "differential_evolution step 48: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0021208005247105484\n",
      "\n",
      "differential_evolution step 49: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0017385133202519308\n",
      "\n",
      "differential_evolution step 50: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0017385133202519308\n",
      "\n",
      "differential_evolution step 51: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0017135237273680438\n",
      "\n",
      "differential_evolution step 52: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0010907333866894812\n",
      "\n",
      "differential_evolution step 53: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00043656494134934864\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 54: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0002611833518185651\n",
      "\n",
      "differential_evolution step 55: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00025393159841887206\n",
      "\n",
      "differential_evolution step 56: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00025393159841887206\n",
      "\n",
      "differential_evolution step 57: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00023832833304462527\n",
      "\n",
      "differential_evolution step 58: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00023340277109003637\n",
      "\n",
      "differential_evolution step 59: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.00016734012602537683\n",
      "\n",
      "differential_evolution step 60: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 5.372070257621572e-05\n",
      "\n",
      "differential_evolution step 61: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0001588296116064249\n",
      "\n",
      "differential_evolution step 62: f(x)= -14.1403\n",
      "params = [37.66449239  0.83484603  0.11991495  0.82663926  2.58667833]; convergence = 0.0003844107596975118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-9:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-2:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; convergence = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvergence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWalker750\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:329\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    317\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    318\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                  constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[1;32m    328\u001b[0m                                  x0\u001b[38;5;241m=\u001b[39mx0) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:852\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 852\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:1209\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m trial_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_population_members, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# only calculate for feasible entries\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m trial_energies[feasible] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_population_energies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeasible\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# which solutions are 'improved'?\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m loc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accept_trial(\u001b[38;5;241m*\u001b[39mval) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m        \u001b[38;5;28mzip\u001b[39m(trial_energies, feasible, cv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_energies,\n\u001b[1;32m   1215\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeasible, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_violation)]\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:968\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver._calculate_population_energies\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m    966\u001b[0m parameters_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_parameters(population)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnfevs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    970\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(calc_energies)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# wrong number of arguments for _mapwrapper\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# or wrong length returned from the mapper\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/_lib/_util.py:477\u001b[0m, in \u001b[0;36mMapWrapper.__call__\u001b[0;34m(self, func, iterable)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# only accept one iterable because that's all Pool.map accepts\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;66;03m# wrong number of arguments\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe map-like callable must be of the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m form f(func, iterable)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# params0 = [1]        # u0, b, w, k_action\n",
    "\n",
    "bounds = [(0.9, 40), (0.4, 1.3), (0.05, 0.2), (0.5, 1), (0.3, 6)]\n",
    "#                                                       k_action\n",
    "\n",
    "n_iter = 200\n",
    "pbar = tqdm(total=n_iter)\n",
    "\n",
    "def callback(x, convergence):\n",
    "    print(f'params = {x}; convergence = {convergence}\\n')\n",
    "    with open('params.log', 'a') as f:\n",
    "        f.write(f'params = {x}; convergence = {convergence}\\n')\n",
    "    pbar.update(1)\n",
    "\n",
    "res = differential_evolution(Walker750.calc_reward, bounds, maxiter=n_iter, callback=callback,\n",
    "                             disp=True, updating='deferred', workers=9)\n",
    "pbar.close()\n",
    "\n",
    "# 16 - 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebf5e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T12:54:55.663526Z",
     "start_time": "2022-07-16T09:16:29.670197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4080a49ab5145a39c031b3dcb3873d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -9.91902\n",
      "params = [-0.1317005   0.76049046 -0.19330777  0.05666789  1.34308943  0.12920223\n",
      " -0.24332682  0.2166895   0.64679905  1.88335474]; convergence = 0.010426132705031455\n",
      "\n",
      "differential_evolution step 2: f(x)= -9.91902\n",
      "params = [-0.1317005   0.76049046 -0.19330777  0.05666789  1.34308943  0.12920223\n",
      " -0.24332682  0.2166895   0.64679905  1.88335474]; convergence = 0.008377656174895477\n",
      "\n",
      "differential_evolution step 3: f(x)= -9.91902\n",
      "params = [-0.1317005   0.76049046 -0.19330777  0.05666789  1.34308943  0.12920223\n",
      " -0.24332682  0.2166895   0.64679905  1.88335474]; convergence = 0.006810851255212134\n",
      "\n",
      "differential_evolution step 4: f(x)= -9.91902\n",
      "params = [-0.1317005   0.76049046 -0.19330777  0.05666789  1.34308943  0.12920223\n",
      " -0.24332682  0.2166895   0.64679905  1.88335474]; convergence = 0.005622940800866715\n",
      "\n",
      "differential_evolution step 5: f(x)= -9.91902\n",
      "params = [-0.1317005   0.76049046 -0.19330777  0.05666789  1.34308943  0.12920223\n",
      " -0.24332682  0.2166895   0.64679905  1.88335474]; convergence = 0.005067440058141939\n",
      "\n",
      "differential_evolution step 6: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.004184217536646753\n",
      "\n",
      "differential_evolution step 7: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.003504652570987887\n",
      "\n",
      "differential_evolution step 8: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.00287425405328185\n",
      "\n",
      "differential_evolution step 9: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0025086145375307826\n",
      "\n",
      "differential_evolution step 10: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0018520494825440598\n",
      "\n",
      "differential_evolution step 11: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0014413408204980598\n",
      "\n",
      "differential_evolution step 12: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0010120643314840427\n",
      "\n",
      "differential_evolution step 13: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0007679093915662021\n",
      "\n",
      "differential_evolution step 14: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.00045738889895687913\n",
      "\n",
      "differential_evolution step 15: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.00015960065485774117\n",
      "\n",
      "differential_evolution step 16: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.00023455157703746382\n",
      "\n",
      "differential_evolution step 17: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0005230635008070188\n",
      "\n",
      "differential_evolution step 18: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0012289408120786977\n",
      "\n",
      "differential_evolution step 19: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0015246883827119847\n",
      "\n",
      "differential_evolution step 20: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0019422032766732201\n",
      "\n",
      "differential_evolution step 21: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0049373302590166234\n",
      "\n",
      "differential_evolution step 22: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.005486116557346336\n",
      "\n",
      "differential_evolution step 23: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.006261402835722119\n",
      "\n",
      "differential_evolution step 24: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.006645449129374118\n",
      "\n",
      "differential_evolution step 25: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.006943527213152243\n",
      "\n",
      "differential_evolution step 26: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.007161422460011546\n",
      "\n",
      "differential_evolution step 27: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0074820891523020945\n",
      "\n",
      "differential_evolution step 28: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.007738109038391023\n",
      "\n",
      "differential_evolution step 29: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.007846537432557263\n",
      "\n",
      "differential_evolution step 30: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.008686020736145125\n",
      "\n",
      "differential_evolution step 31: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.0088437065378154\n",
      "\n",
      "differential_evolution step 32: f(x)= -21.5932\n",
      "params = [ 0.44924203  0.72794723 -0.49852452 -0.35494599  0.0859324  -0.19954048\n",
      " -0.44971128  0.21221948  0.84354148  1.86184146]; convergence = 0.009155236880461657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-9:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; convergence = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvergence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWalker750\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:329\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    317\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    318\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                  constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[1;32m    328\u001b[0m                                  x0\u001b[38;5;241m=\u001b[39mx0) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:852\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 852\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:1209\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m trial_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_population_members, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# only calculate for feasible entries\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m trial_energies[feasible] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_population_energies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeasible\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# which solutions are 'improved'?\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m loc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accept_trial(\u001b[38;5;241m*\u001b[39mval) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m        \u001b[38;5;28mzip\u001b[39m(trial_energies, feasible, cv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_energies,\n\u001b[1;32m   1215\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeasible, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_violation)]\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:968\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver._calculate_population_energies\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m    966\u001b[0m parameters_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_parameters(population)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnfevs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    970\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(calc_energies)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# wrong number of arguments for _mapwrapper\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# or wrong length returned from the mapper\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/_lib/_util.py:477\u001b[0m, in \u001b[0;36mMapWrapper.__call__\u001b[0;34m(self, func, iterable)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# only accept one iterable because that's all Pool.map accepts\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;66;03m# wrong number of arguments\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe map-like callable must be of the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m form f(func, iterable)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bounds = [(-0.5, 1.5) for _ in range(8)] + [(0.4, 1.2), (0.9, 4)]\n",
    "#             u_init                            u0      k_action\n",
    "\n",
    "n_iter = 200\n",
    "pbar = tqdm(total=n_iter)\n",
    "\n",
    "def callback(x, convergence):\n",
    "    print(f'params = {x}; convergence = {convergence}\\n')\n",
    "    with open('params.log', 'a') as f:\n",
    "        f.write(f'params = {x}; convergence = {convergence}\\n')\n",
    "    pbar.update(1)\n",
    "\n",
    "res = differential_evolution(Walker750.calc_reward, bounds, maxiter=n_iter, callback=callback,\n",
    "                             disp=True, updating='deferred', workers=9)\n",
    "pbar.close()\n",
    "\n",
    "# 16 - 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5ac4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:43:12.090812Z",
     "start_time": "2022-07-16T05:43:12.090806Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [-3.08761372, -1.77306303, -1.41658687, -1.46172341, 0.04756068,\n",
    "          0.17430144, 0.99882352, 0.84377149, 0.20099308, 0.71020467,\n",
    "          1.46892851, 0.61687972, -1.89211497] # ~-9 by 300 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdc013f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:43:14.586303Z",
     "start_time": "2022-07-16T05:43:14.576882Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [-0.94446406, -0.54692928, -1.55172582, -1.56532573,  0.11850464,  0.28698917,\n",
    "  0.48018673 , 0.14982722 , 0.18285041 , 0.64192383 , 1.75345794 , 1.28501733,\n",
    " -1.56852236,  1.95418607] # ~-6.3 by 750 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c156ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:11:25.497961Z",
     "start_time": "2022-07-16T07:11:25.491584Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [36.5335856, 2.23219068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8d3d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:12:15.685208Z",
     "start_time": "2022-07-16T07:11:31.713246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BipedalWalker-v3')\n",
    "c = Walker750.make_controller(params)\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(500):\n",
    "    y = c.step(observation)\n",
    "    action = np.array([y[Side.LEFT][Joint.HIP], y[Side.LEFT][Joint.KNEE], \n",
    "                       y[Side.RIGHT][Joint.HIP], y[Side.RIGHT][Joint.KNEE]])\n",
    "    action = np.clip(action, -1, 1) * params[-1]\n",
    "#     print(action)\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "#     print(done, info)\n",
    "#     print(reward)\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d86f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d00f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d92585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T21:36:01.140894Z",
     "start_time": "2022-07-15T17:01:55.548462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de1c909af484cce8c56a34c01635911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -4.39393\n",
      "params = [-3.59501631 -1.96946159 -1.93599384 -2.98718828  0.06744325  0.76629448\n",
      "  0.77100639  0.84867654  0.245692    0.20664682  1.66493787  3.04727016\n",
      " -3.26314092]; convergence = 0.021701426301044484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 2: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.015623368240949908\n",
      "\n",
      "differential_evolution step 3: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.012697495616765378\n",
      "\n",
      "differential_evolution step 4: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.011565376246480548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 5: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.010155272730808827\n",
      "\n",
      "differential_evolution step 6: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.00902440114032724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 7: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.00839711415557786\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 8: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.00784940731434265\n",
      "\n",
      "differential_evolution step 9: f(x)= -7.22247\n",
      "params = [-2.20556849 -1.20086706 -2.77422706 -3.89954667  0.10247838  0.33474281\n",
      "  0.94208367  0.8718785   0.05389132  0.7020375   1.66070194  2.37595228\n",
      " -2.63775282]; convergence = 0.007489940360820588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 10: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.006962592949868118\n",
      "\n",
      "differential_evolution step 11: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.0064183020053065155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 12: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.0058150842330258025\n",
      "\n",
      "differential_evolution step 13: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.005521482183858114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 14: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.00499685343149184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 15: f(x)= -8.79905\n",
      "params = [-2.65184745 -1.35015601 -0.48389503 -3.19365567  0.08874524  0.58334018\n",
      "  0.21511057  0.44621117  0.13452008  0.98420567  0.98154589  2.14943601\n",
      " -3.65282688]; convergence = 0.004507893822527796\n",
      "\n",
      "differential_evolution step 16: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.004121848872964966\n",
      "\n",
      "differential_evolution step 17: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0035755971679981647\n",
      "\n",
      "differential_evolution step 18: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.003255207462738991\n",
      "\n",
      "differential_evolution step 19: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0029327284999837552\n",
      "\n",
      "differential_evolution step 20: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.002610386918325615\n",
      "\n",
      "differential_evolution step 21: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0022862494540487597\n",
      "\n",
      "differential_evolution step 22: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0020013876239017266\n",
      "\n",
      "differential_evolution step 23: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0016762421222667094\n",
      "\n",
      "differential_evolution step 24: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0014619128925191696\n",
      "\n",
      "differential_evolution step 25: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0012056765945885751\n",
      "\n",
      "differential_evolution step 26: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0010808941235308687\n",
      "\n",
      "differential_evolution step 27: f(x)= -9.46665\n",
      "params = [-2.37988156 -0.57045996 -0.44796019 -2.09748504  0.05152587  0.53397537\n",
      "  0.68364041  0.72422452  0.14398645  0.9409249   0.75844534  1.3655779\n",
      " -2.10738934]; convergence = 0.0010236663210790127\n",
      "\n",
      "differential_evolution step 28: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0009065957157787657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 29: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.00047563047513268477\n",
      "\n",
      "differential_evolution step 30: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0009814635063849244\n",
      "\n",
      "differential_evolution step 31: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0011112451069740196\n",
      "\n",
      "differential_evolution step 32: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0013203943032774805\n",
      "\n",
      "differential_evolution step 33: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0013983412906731262\n",
      "\n",
      "differential_evolution step 34: f(x)= -10.6116\n",
      "params = [-3.64928681 -0.76019872 -0.08499677 -1.52791392  0.09321199  0.28533522\n",
      "  0.5546173   0.30459492  0.37909222  0.9503901   0.95159424  3.12808597\n",
      " -3.00181349]; convergence = 0.0015291949907403394\n",
      "\n",
      "differential_evolution step 35: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.002413927506307433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 36: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.0026775359231277266\n",
      "\n",
      "differential_evolution step 37: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.0028319269352328337\n",
      "\n",
      "differential_evolution step 38: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.004452885714888074\n",
      "\n",
      "differential_evolution step 39: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.004836526102729711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_2's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 40: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.004873973885332039\n",
      "\n",
      "differential_evolution step 41: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.00510826101432396\n",
      "\n",
      "differential_evolution step 42: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.005269490057729657\n",
      "\n",
      "differential_evolution step 43: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.00552116925099914\n",
      "\n",
      "differential_evolution step 44: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.005673349430054783\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 45: f(x)= -12.5091\n",
      "params = [-3.4461988  -0.58917578 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.95350655  0.3903604   3.11850834\n",
      " -2.41093854]; convergence = 0.005752413059288117\n",
      "\n",
      "differential_evolution step 46: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.0059293562332821854\n",
      "\n",
      "differential_evolution step 47: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.00601223838268291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 48: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.015862274459282153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 49: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.015915054331402688\n",
      "\n",
      "differential_evolution step 50: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.016415025038282904\n",
      "\n",
      "differential_evolution step 51: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.01651108486910488\n",
      "\n",
      "differential_evolution step 52: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.01672329017173743\n",
      "\n",
      "differential_evolution step 53: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.016836329356155144\n",
      "\n",
      "differential_evolution step 54: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.017541743988483603\n",
      "\n",
      "differential_evolution step 55: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.01777744053232436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 56: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.018226122210450117\n",
      "\n",
      "differential_evolution step 57: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.018332498734831643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 58: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.027405580241070187\n",
      "\n",
      "differential_evolution step 59: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.028054384215170074\n",
      "\n",
      "differential_evolution step 60: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.028447989573145392\n",
      "\n",
      "differential_evolution step 61: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.028973964576058605\n",
      "\n",
      "differential_evolution step 62: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.02936260229739788\n",
      "\n",
      "differential_evolution step 63: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.02938263616623972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 64: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.029783840544212684\n",
      "\n",
      "differential_evolution step 65: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03049356729822042\n",
      "\n",
      "differential_evolution step 66: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.031120262835817487\n",
      "\n",
      "differential_evolution step 67: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03163756953081021\n",
      "\n",
      "differential_evolution step 68: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03187081646912669\n",
      "\n",
      "differential_evolution step 69: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03239602984648373\n",
      "\n",
      "differential_evolution step 70: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.032250199013700936\n",
      "\n",
      "differential_evolution step 71: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03192325749285454\n",
      "\n",
      "differential_evolution step 72: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.033036782054793004\n",
      "\n",
      "differential_evolution step 73: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03349291257811352\n",
      "\n",
      "differential_evolution step 74: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03373477924376907\n",
      "\n",
      "differential_evolution step 75: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03388581632466205\n",
      "\n",
      "differential_evolution step 76: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03403532156851901\n",
      "\n",
      "differential_evolution step 77: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.03464480263144371\n",
      "\n",
      "differential_evolution step 78: f(x)= -15.1066\n",
      "params = [-3.4461988  -1.45759603 -0.08612545 -1.23793089  0.06099851  0.08650222\n",
      "  0.79307611  0.60719265  0.28579553  0.99434202  0.6234583   3.11850834\n",
      " -2.41093854]; convergence = 0.035210186860034895\n",
      "\n",
      "differential_evolution step 79: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03245452170671133\n",
      "\n",
      "differential_evolution step 80: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03254002976268933\n",
      "\n",
      "differential_evolution step 81: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.031332273001543454\n",
      "\n",
      "differential_evolution step 82: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03167566495354211\n",
      "\n",
      "differential_evolution step 83: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03167566495354211\n",
      "\n",
      "differential_evolution step 84: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03239599397763031\n",
      "\n",
      "differential_evolution step 85: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.032924066881507466\n",
      "\n",
      "differential_evolution step 86: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03361872043317244\n",
      "\n",
      "differential_evolution step 87: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03384021540111191\n",
      "\n",
      "differential_evolution step 88: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03476603469102741\n",
      "\n",
      "differential_evolution step 89: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03480466644385259\n",
      "\n",
      "differential_evolution step 90: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.035523087964001734\n",
      "\n",
      "differential_evolution step 91: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03502075117293897\n",
      "\n",
      "differential_evolution step 92: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03563174172906331\n",
      "\n",
      "differential_evolution step 93: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03609033187171164\n",
      "\n",
      "differential_evolution step 94: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.036015480221185246\n",
      "\n",
      "differential_evolution step 95: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03620274180651158\n",
      "\n",
      "differential_evolution step 96: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.0364600027771799\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 97: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.036795447955820355\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 98: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03691051258042287\n",
      "\n",
      "differential_evolution step 99: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.037509828930223\n",
      "\n",
      "differential_evolution step 100: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03766381237025796\n",
      "\n",
      "differential_evolution step 101: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03817650253568494\n",
      "\n",
      "differential_evolution step 102: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.03825358686506619\n",
      "\n",
      "differential_evolution step 103: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.038983920465211604\n",
      "\n",
      "differential_evolution step 104: f(x)= -20.0617\n",
      "params = [-3.15788288 -0.41961284 -2.6157932  -2.67779105  0.07335032  0.10212809\n",
      "  0.64912344  0.64802246  0.20336929  0.99670978  0.47047603  2.30910493\n",
      " -2.91164797]; convergence = 0.038947735825391495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-9:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; convergence = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvergence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWalker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:329\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    317\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    318\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                  constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[1;32m    328\u001b[0m                                  x0\u001b[38;5;241m=\u001b[39mx0) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:852\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 852\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:1209\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m trial_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_population_members, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# only calculate for feasible entries\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m trial_energies[feasible] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_population_energies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeasible\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;66;03m# which solutions are 'improved'?\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m loc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accept_trial(\u001b[38;5;241m*\u001b[39mval) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m        \u001b[38;5;28mzip\u001b[39m(trial_energies, feasible, cv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_energies,\n\u001b[1;32m   1215\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeasible, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint_violation)]\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:968\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver._calculate_population_energies\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m    966\u001b[0m parameters_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_parameters(population)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mparameters_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnfevs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    970\u001b[0m     calc_energies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(calc_energies)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# wrong number of arguments for _mapwrapper\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# or wrong length returned from the mapper\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/_lib/_util.py:477\u001b[0m, in \u001b[0;36mMapWrapper.__call__\u001b[0;34m(self, func, iterable)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# only accept one iterable because that's all Pool.map accepts\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;66;03m# wrong number of arguments\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe map-like callable must be of the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m form f(func, iterable)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params0 = [-0.607, -0.311, -1.649, -1.934, # w1-w8\n",
    "           0.285, 0.143, 0.302, 0.151,     # tau\n",
    "           0.124, 0.770,                   # a\n",
    "           0.805, 3.078, -2.120]           # u0, b, w\n",
    "\n",
    "#          w1-w8                           tau\n",
    "bounds = [(-4, 0) for _ in range(4)] + [(0.04, 1) for _ in range(4)] +\\\n",
    "         [(0.03, 1) for _ in range(2)] + [(0, 2), (0, 4), (-4, 0)]\n",
    "#             a                              u0      b       w\n",
    "\n",
    "n_iter = 150\n",
    "pbar = tqdm(total=n_iter)\n",
    "\n",
    "def callback(x, convergence):\n",
    "    print(f'params = {x}; convergence = {convergence}\\n')\n",
    "    with open('params.log', 'a') as f:\n",
    "        f.write(f'params = {x}; convergence = {convergence}\\n')\n",
    "    pbar.update(1)\n",
    "\n",
    "res = differential_evolution(Walker.calc_reward, bounds, maxiter=n_iter, callback=callback,\n",
    "                             disp=True, x0=params0, updating='deferred', workers=9)\n",
    "pbar.close()\n",
    "\n",
    "# 16 - 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67270bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:43:12.088082Z",
     "start_time": "2022-07-15T21:42:53.188578Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cda1479ad3e40ed8ff5c7afc39ee7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/parsing/bast.py:60: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  bool_dtype =numpy.dtype(numpy.bool)\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/clocks.py:95: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.float, read_only=True, constant=True,\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n",
      "/Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/__init__.py:85: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not LooseVersion(module.__version__) >= LooseVersion(version):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 27.5779\n",
      "params = [-0.42501264 -0.58253985 -1.69242264 -2.1929866   0.13932816  0.31388793\n",
      "  0.15285687  0.10933013  0.08600884  0.85332607  0.25974358  2.51674153\n",
      " -2.4567572   6.50110786]; convergence = 0.06744375546486671\n",
      "\n",
      "differential_evolution step 2: f(x)= 9.41922\n",
      "params = [-0.73098689 -0.42082687 -1.64843058 -1.85408841  0.40353238  0.27325853\n",
      "  0.16828233  0.48454135  0.10234386  0.7785963   0.22432045  2.96584888\n",
      " -1.99759968  1.6434837 ]; convergence = 0.0512814859385159\n",
      "\n",
      "differential_evolution step 3: f(x)= 9.41922\n",
      "params = [-0.73098689 -0.42082687 -1.64843058 -1.85408841  0.40353238  0.27325853\n",
      "  0.16828233  0.48454135  0.10234386  0.7785963   0.22432045  2.96584888\n",
      " -1.99759968  1.6434837 ]; convergence = 0.04000723417437417\n",
      "\n",
      "differential_evolution step 4: f(x)= 9.41922\n",
      "params = [-0.73098689 -0.42082687 -1.64843058 -1.85408841  0.40353238  0.27325853\n",
      "  0.16828233  0.48454135  0.10234386  0.7785963   0.22432045  2.96584888\n",
      " -1.99759968  1.6434837 ]; convergence = 0.036782663227095724\n",
      "\n",
      "differential_evolution step 5: f(x)= 9.41922\n",
      "params = [-0.73098689 -0.42082687 -1.64843058 -1.85408841  0.40353238  0.27325853\n",
      "  0.16828233  0.48454135  0.10234386  0.7785963   0.22432045  2.96584888\n",
      " -1.99759968  1.6434837 ]; convergence = 0.03444734594202976\n",
      "\n",
      "differential_evolution step 6: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.030705719291640416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 7: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.029269904812335212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 8: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.026856354905410648\n",
      "\n",
      "differential_evolution step 9: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.02505464501269984\n",
      "\n",
      "differential_evolution step 10: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.023423934566100032\n",
      "\n",
      "differential_evolution step 11: f(x)= 1.19713\n",
      "params = [-0.59627589 -0.88761326 -2.014321   -1.86565133  0.1218578   0.19871013\n",
      "  0.34428069  0.28638777  0.19787792  0.59218007  0.36462956  3.08291402\n",
      " -1.71436912  2.1873345 ]; convergence = 0.022516955844413\n",
      "\n",
      "differential_evolution step 12: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.020834659715145976\n",
      "\n",
      "differential_evolution step 13: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.02030684280249453\n",
      "\n",
      "differential_evolution step 14: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.020059401652298678\n",
      "\n",
      "differential_evolution step 15: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.019598400760104315\n",
      "\n",
      "differential_evolution step 16: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.019109410914131722\n",
      "\n",
      "differential_evolution step 17: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.018237609543649187\n",
      "\n",
      "differential_evolution step 18: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.018086279779807497\n",
      "\n",
      "differential_evolution step 19: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.01797598643385184\n",
      "\n",
      "differential_evolution step 20: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.01764426805445549\n",
      "\n",
      "differential_evolution step 21: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.01744324160292276\n",
      "\n",
      "differential_evolution step 22: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.017286966203542004\n",
      "\n",
      "differential_evolution step 23: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.01668541983399062\n",
      "\n",
      "differential_evolution step 24: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.016593885434311374\n",
      "\n",
      "differential_evolution step 25: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.01654303481033269\n",
      "\n",
      "differential_evolution step 26: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.015889192064859652\n",
      "\n",
      "differential_evolution step 27: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.015628677648828568\n",
      "\n",
      "differential_evolution step 28: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.0155245571268321\n",
      "\n",
      "differential_evolution step 29: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.014986966769537991\n",
      "\n",
      "differential_evolution step 30: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.014800984925340934\n",
      "\n",
      "differential_evolution step 31: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.014650793911154897\n",
      "\n",
      "differential_evolution step 32: f(x)= -2.1122\n",
      "params = [-0.57496469 -0.53072593 -1.55296262 -1.83919641  0.16968515  0.11087585\n",
      "  0.40989053  0.20554433  0.16582815  0.66838412  1.30854683  3.53735298\n",
      " -1.68228604  1.89121554]; convergence = 0.014428887808131566\n",
      "\n",
      "differential_evolution step 33: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.014017310411195662\n",
      "\n",
      "differential_evolution step 34: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013987021940668204\n",
      "\n",
      "differential_evolution step 35: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013835281446193328\n",
      "\n",
      "differential_evolution step 36: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013696195884630879\n",
      "\n",
      "differential_evolution step 37: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013615746552832453\n",
      "\n",
      "differential_evolution step 38: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013314489192241374\n",
      "\n",
      "differential_evolution step 39: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.013254123829144353\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 40: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01297453629240089\n",
      "\n",
      "differential_evolution step 41: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.012855537785353604\n",
      "\n",
      "differential_evolution step 42: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01276308776624194\n",
      "\n",
      "differential_evolution step 43: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.012743023572625354\n",
      "\n",
      "differential_evolution step 44: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.012552963778942803\n",
      "\n",
      "differential_evolution step 45: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.012533430700314614\n",
      "\n",
      "differential_evolution step 46: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.012233681807221454\n",
      "\n",
      "differential_evolution step 47: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01210406128898558\n",
      "\n",
      "differential_evolution step 48: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011959767961876547\n",
      "\n",
      "differential_evolution step 49: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011846704734124377\n",
      "\n",
      "differential_evolution step 50: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011758862897687192\n",
      "\n",
      "differential_evolution step 51: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011743924670674142\n",
      "\n",
      "differential_evolution step 52: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011645998457422212\n",
      "\n",
      "differential_evolution step 53: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01161322200746749\n",
      "\n",
      "differential_evolution step 54: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01140795247511721\n",
      "\n",
      "differential_evolution step 55: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011336589413071758\n",
      "\n",
      "differential_evolution step 56: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011339809759316187\n",
      "\n",
      "differential_evolution step 57: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011283108541152755\n",
      "\n",
      "differential_evolution step 58: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.011246734177021652\n",
      "\n",
      "differential_evolution step 59: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01109405160305642\n",
      "\n",
      "differential_evolution step 60: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.0110123942342183\n",
      "\n",
      "differential_evolution step 61: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010919141999965264\n",
      "\n",
      "differential_evolution step 62: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010898546638879094\n",
      "\n",
      "differential_evolution step 63: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010804044164663372\n",
      "\n",
      "differential_evolution step 64: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010864050207341264\n",
      "\n",
      "differential_evolution step 65: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010795101746843998\n",
      "\n",
      "differential_evolution step 66: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010740106117104626\n",
      "\n",
      "differential_evolution step 67: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010820473236950623\n",
      "\n",
      "differential_evolution step 68: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010869393530982912\n",
      "\n",
      "differential_evolution step 69: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010854317751008051\n",
      "\n",
      "differential_evolution step 70: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010781667233712041\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 71: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010763109925181171\n",
      "\n",
      "differential_evolution step 72: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010709670326224222\n",
      "\n",
      "differential_evolution step 73: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010640101086214264\n",
      "\n",
      "differential_evolution step 74: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010594123282221193\n",
      "\n",
      "differential_evolution step 75: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01053064535821663\n",
      "\n",
      "differential_evolution step 76: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010503395134206766\n",
      "\n",
      "differential_evolution step 77: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010403991312299597\n",
      "\n",
      "differential_evolution step 78: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010283331077704632\n",
      "\n",
      "differential_evolution step 79: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.01015390261855305\n",
      "\n",
      "differential_evolution step 80: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.010036280994659396\n",
      "\n",
      "differential_evolution step 81: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.009836820776046374\n",
      "\n",
      "differential_evolution step 82: f(x)= -6.28966\n",
      "params = [-0.94209612 -0.60991611 -1.83050304 -1.86959833  0.19861204  0.23845201\n",
      "  0.3876259   0.25169525  0.16064255  0.62429496  1.81064038  2.72728617\n",
      " -1.99142156  2.25271611]; convergence = 0.009701624141024429\n",
      "\n",
      "differential_evolution step 83: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009599539242999796\n",
      "\n",
      "differential_evolution step 84: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009590251266747047\n",
      "\n",
      "differential_evolution step 85: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009489259192891817\n",
      "\n",
      "differential_evolution step 86: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009414363717232081\n",
      "\n",
      "differential_evolution step 87: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009514776923972137\n",
      "\n",
      "differential_evolution step 88: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009609718740143955\n",
      "\n",
      "differential_evolution step 89: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009557562456956712\n",
      "\n",
      "differential_evolution step 90: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009590241185830333\n",
      "\n",
      "differential_evolution step 91: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009580017121769499\n",
      "\n",
      "differential_evolution step 92: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009580017121769499\n",
      "\n",
      "differential_evolution step 93: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009565032384985501\n",
      "\n",
      "differential_evolution step 94: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009565032384985501\n",
      "\n",
      "differential_evolution step 95: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009495597077683387\n",
      "\n",
      "differential_evolution step 96: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00947224268632184\n",
      "\n",
      "differential_evolution step 97: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009385384879904958\n",
      "\n",
      "differential_evolution step 98: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00938331865686532\n",
      "\n",
      "differential_evolution step 99: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009487319556720993\n",
      "\n",
      "differential_evolution step 100: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00944665408113345\n",
      "\n",
      "differential_evolution step 101: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00937876387047653\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 102: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009540488729659388\n",
      "\n",
      "differential_evolution step 103: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009537708428195086\n",
      "\n",
      "differential_evolution step 104: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009505972430058456\n",
      "\n",
      "differential_evolution step 105: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009443939881533992\n",
      "\n",
      "differential_evolution step 106: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009397070475053296\n",
      "\n",
      "differential_evolution step 107: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009336303953225824\n",
      "\n",
      "differential_evolution step 108: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009326922706205321\n",
      "\n",
      "differential_evolution step 109: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009239777507448147\n",
      "\n",
      "differential_evolution step 110: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009229438285816417\n",
      "\n",
      "differential_evolution step 111: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009110018623610525\n",
      "\n",
      "differential_evolution step 112: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009190412564928528\n",
      "\n",
      "differential_evolution step 113: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00934172559771756\n",
      "\n",
      "differential_evolution step 114: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009289551574449084\n",
      "\n",
      "differential_evolution step 115: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009279392428047784\n",
      "\n",
      "differential_evolution step 116: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009284715745260106\n",
      "\n",
      "differential_evolution step 117: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009479365835221893\n",
      "\n",
      "differential_evolution step 118: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009416868405142687\n",
      "\n",
      "differential_evolution step 119: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009654865534998083\n",
      "\n",
      "differential_evolution step 120: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009654494231532496\n",
      "\n",
      "differential_evolution step 121: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009654494231532496\n",
      "\n",
      "differential_evolution step 122: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009632031666121416\n",
      "\n",
      "differential_evolution step 123: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009588147179853191\n",
      "\n",
      "differential_evolution step 124: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009600387391619666\n",
      "\n",
      "differential_evolution step 125: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009600387391619666\n",
      "\n",
      "differential_evolution step 126: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009560015013011326\n",
      "\n",
      "differential_evolution step 127: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009560015013011326\n",
      "\n",
      "differential_evolution step 128: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.0095482676272827\n",
      "\n",
      "differential_evolution step 129: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009530254447621837\n",
      "\n",
      "differential_evolution step 130: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.01015937882860523\n",
      "\n",
      "differential_evolution step 131: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.010154739106665134\n",
      "\n",
      "differential_evolution step 132: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.010153747084654014\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 133: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.010098811114323907\n",
      "\n",
      "differential_evolution step 134: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.010098623326871092\n",
      "\n",
      "differential_evolution step 135: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009985116624798318\n",
      "\n",
      "differential_evolution step 136: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009931493877498192\n",
      "\n",
      "differential_evolution step 137: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009908780266703226\n",
      "\n",
      "differential_evolution step 138: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009767782375270392\n",
      "\n",
      "differential_evolution step 139: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009736844602907904\n",
      "\n",
      "differential_evolution step 140: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.00968156569116059\n",
      "\n",
      "differential_evolution step 141: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009630819380943264\n",
      "\n",
      "differential_evolution step 142: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009630819380943264\n",
      "\n",
      "differential_evolution step 143: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009624447437584433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    neurongroup_1's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'u1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_1's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v1' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n",
      "WARNING    neurongroup_3's variable 'v2' has NaN, very large values, or encountered an error in numerical integration. This is usually a sign that an unstable or invalid integration method was chosen. [brian2.groups.group.invalid_values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 144: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009613792551979547\n",
      "\n",
      "differential_evolution step 145: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009616645027033634\n",
      "\n",
      "differential_evolution step 146: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009617329148217679\n",
      "\n",
      "differential_evolution step 147: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009538958937739744\n",
      "\n",
      "differential_evolution step 148: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009494063083008056\n",
      "\n",
      "differential_evolution step 149: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009410982908483596\n",
      "\n",
      "differential_evolution step 150: f(x)= -6.36237\n",
      "params = [-0.94446406 -0.54692928 -1.55172582 -1.56532573  0.11850464  0.28698917\n",
      "  0.48018673  0.14982722  0.18285041  0.64192383  1.75345794  1.28501733\n",
      " -1.56852236  1.95418607]; convergence = 0.009368383527227983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang-13: error: the clang compiler does not support '-march=native'\n",
      "WARNING    Cannot use Cython, a test compilation failed: command '/Users/aleks311001/mambaforge/envs/neuro/bin/arm64-apple-darwin20.0.0-clang' failed with exit code 1 (CompileError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n",
      "Process SpawnPoolWorker-9:\n",
      "Process SpawnPoolWorker-5:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-2:\n",
      "WARNING    /Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/units/fundamentalunits.py:2262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if d is 1 or d is DIMENSIONLESS:\n",
      " [py.warnings]\n",
      "WARNING    /Users/aleks311001/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/units/fundamentalunits.py:2262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if d is 1 or d is DIMENSIONLESS:\n",
      " [py.warnings]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; convergence = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvergence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWalker750\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_reward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeferred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:329\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    317\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    318\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                  constraints\u001b[38;5;241m=\u001b[39mconstraints,\n\u001b[1;32m    328\u001b[0m                                  x0\u001b[38;5;241m=\u001b[39mx0) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:903\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(constr_violation \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.\u001b[39m):\n\u001b[1;32m    898\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferential evolution didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    899\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m solution satisfying the constraints,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    900\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m attempting to polish from the least\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m infeasible solution\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 903\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDE_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolish_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mnfev\n\u001b[1;32m    910\u001b[0m DE_result\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_minimize.py:692\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    689\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    690\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 692\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    695\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    696\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/scipy/_lib/_util.py:407\u001b[0m, in \u001b[0;36m_FunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AIRI/WalkerBI/Walker750.py:240\u001b[0m, in \u001b[0;36mcalc_reward\u001b[0;34m(params, n_iter)\u001b[0m\n\u001b[1;32m    224\u001b[0m #     with warnings.catch_warnings():\n\u001b[1;32m    225\u001b[0m #         warnings.filterwarnings(action='ignore', category=DeprecationWarning, module='.*brian2.*')\n\u001b[1;32m    226\u001b[0m #         warnings.filterwarnings(action='ignore', category=DeprecationWarning,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m #         warnings.filterwarnings(action='ignore', category=UserWarning,\n\u001b[1;32m    233\u001b[0m #                                 message='.*WARN: We recommend you to use a symmetric and normalized Box action space.*')\n\u001b[1;32m    235\u001b[0m     env = gym.make('BipedalWalker-v3')\n\u001b[1;32m    236\u001b[0m     #     c = Controller(w=params[:8],\n\u001b[1;32m    237\u001b[0m     #                    u_init={\n\u001b[1;32m    238\u001b[0m     #                        Side.LEFT: {Joint.HIP: params[8:10], Joint.KNEE: params[10:12]},\n\u001b[1;32m    239\u001b[0m     #                        Side.RIGHT: {Joint.HIP: params[12:14], Joint.KNEE: params[14:16]},\n\u001b[0;32m--> 240\u001b[0m     #                    },\n\u001b[1;32m    241\u001b[0m     #                    tau={\n\u001b[1;32m    242\u001b[0m     #                        'u': {Joint.HIP: params[16], Joint.KNEE: params[17]},\n\u001b[1;32m    243\u001b[0m     #                        'v': {Joint.HIP: params[18], Joint.KNEE: params[19]},\n\u001b[1;32m    244\u001b[0m     #                    }, a=params[20:22], u0=params[22], b=params[23],\n\u001b[1;32m    245\u001b[0m     #                    w_joint=params[24], t_step=20 * b2.ms)\n\u001b[1;32m    247\u001b[0m     c = make_controller(params[:-1])\n\u001b[1;32m    249\u001b[0m     observation = env.reset()\n",
      "File \u001b[0;32m~/AIRI/WalkerBI/Walker750.py:164\u001b[0m, in \u001b[0;36mController.step\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_z()\n\u001b[0;32m--> 164\u001b[0m     y \u001b[38;5;241m=\u001b[39m {s: {j: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoints[s][j]\u001b[38;5;241m.\u001b[39mstep(z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[s][j], f\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf[s][j], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf[s][j]))\n\u001b[1;32m    165\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m Joint} \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m Side}\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m#         self.update_f(y)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AIRI/WalkerBI/Walker750.py:164\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_z()\n\u001b[0;32m--> 164\u001b[0m     y \u001b[38;5;241m=\u001b[39m {s: {j: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoints[s][j]\u001b[38;5;241m.\u001b[39mstep(z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[s][j], f\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf[s][j], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf[s][j]))\n\u001b[1;32m    165\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m Joint} \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m Side}\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m#         self.update_f(y)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AIRI/WalkerBI/Walker750.py:164\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_z()\n\u001b[0;32m--> 164\u001b[0m     y \u001b[38;5;241m=\u001b[39m {s: {j: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m Joint} \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m Side}\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m#         self.update_f(y)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AIRI/WalkerBI/Walker750.py:77\u001b[0m, in \u001b[0;36mJointNeurons.step\u001b[0;34m(self, z, f)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint\u001b[38;5;241m.\u001b[39mf1 \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint\u001b[38;5;241m.\u001b[39mf2 \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m y1, y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_y()\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y1 \u001b[38;5;241m-\u001b[39m y2\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/base.py:280\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/units/fundamentalunits.py:2392\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2383\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{f.__name__}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2384\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected a quantitity with unit \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2385\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{unit}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2386\u001b[0m                              \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{value}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m=\u001b[39mf, k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m   2387\u001b[0m                                                unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(au[k]),\n\u001b[1;32m   2388\u001b[0m                                                value\u001b[38;5;241m=\u001b[39mnewkeyset[k])\n\u001b[1;32m   2389\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(error_message,\n\u001b[1;32m   2390\u001b[0m                                          get_dimensions(newkeyset[k]))\n\u001b[0;32m-> 2392\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[1;32m   2394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m au[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/network.py:1012\u001b[0m, in \u001b[0;36mNetwork.run\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m get_local_namespace(level\u001b[38;5;241m=\u001b[39mlevel\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_objects) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# TODO: raise an error? warning?\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/base.py:280\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/core/network.py:901\u001b[0m, in \u001b[0;36mNetwork.before_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m         \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m brian_object_exception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred when preparing an object.\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj, ex)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/groups/group.py:1111\u001b[0m, in \u001b[0;36mCodeRunner.before_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_abstract_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# If the CodeRunner has variables, add them\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/groups/neurongroup.py:243\u001b[0m, in \u001b[0;36mStateUpdater.update_abstract_code\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabstract_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_refractory_code(run_namespace\u001b[38;5;241m=\u001b[39mrun_namespace)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Get the names used in the refractory code\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m _, used_known, unknown \u001b[38;5;241m=\u001b[39m \u001b[43manalyse_identifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabstract_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Get all names used in the equations (and always get \"dt\")\u001b[39;00m\n\u001b[1;32m    247\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup\u001b[38;5;241m.\u001b[39mequations\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/codegen/translation.py:98\u001b[0m, in \u001b[0;36manalyse_identifiers\u001b[0;34m(code, variables, recursive)\u001b[0m\n\u001b[1;32m     94\u001b[0m     variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((k, Variable(name\u001b[38;5;241m=\u001b[39mk, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64))\n\u001b[1;32m     95\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m known)\n\u001b[1;32m     97\u001b[0m known \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m STANDARD_IDENTIFIERS\n\u001b[0;32m---> 98\u001b[0m scalar_stmts, vector_stmts \u001b[38;5;241m=\u001b[39m \u001b[43mmake_statements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m stmts \u001b[38;5;241m=\u001b[39m scalar_stmts \u001b[38;5;241m+\u001b[39m vector_stmts\n\u001b[1;32m    100\u001b[0m defined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stmt\u001b[38;5;241m.\u001b[39mvar \u001b[38;5;28;01mfor\u001b[39;00m stmt \u001b[38;5;129;01min\u001b[39;00m stmts \u001b[38;5;28;01mif\u001b[39;00m stmt\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:=\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:90\u001b[0m, in \u001b[0;36mcached.<locals>.cached_func\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m         cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([_hashable(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     91\u001b[0m                           [(key, _hashable(value))\n\u001b[1;32m     92\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(kwds\u001b[38;5;241m.\u001b[39mitems())])\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# If we cannot handle a type here, that most likely means that the\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# user provided an argument of a type we don't handle. This will\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# lead to an error message later that is most likely more meaningful\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# to the user than an error message by the caching system\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m# complaining about an unsupported type.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:90\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m         cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     91\u001b[0m                           [(key, _hashable(value))\n\u001b[1;32m     92\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(kwds\u001b[38;5;241m.\u001b[39mitems())])\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# If we cannot handle a type here, that most likely means that the\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;66;03m# user provided an argument of a type we don't handle. This will\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# lead to an error message later that is most likely more meaningful\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;66;03m# to the user than an error message by the caching system\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m# complaining about an unsupported type.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:124\u001b[0m, in \u001b[0;36m_hashable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    122\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:124\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m((_hashable(key), \u001b[43m_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    125\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _of_type(obj_type, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(_hashable(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m obj)\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:121\u001b[0m, in \u001b[0;36m_hashable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m'''Helper function to make a few data structures hashable (e.g. a\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mdictionary gets converted to a frozenset). The function is specifically\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mtailored to our use case and not meant to be generally useful.'''\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_state_tuple\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hashable(\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_tuple\u001b[49m)\n\u001b[1;32m    122\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _of_type(obj_type, Mapping):\n",
      "File \u001b[0;32m~/mambaforge/envs/neuro/lib/python3.10/site-packages/brian2/utils/caching.py:40\u001b[0m, in \u001b[0;36mCacheKey._state_tuple\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_state_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124;03m'''A tuple with this object's attribute values, defining its identity\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    for caching purposes. See `CacheKey` for details.'''\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m                  \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_irrelevant_attributes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params0 = [-0.607, -0.311, -1.649, -1.934, # w1-w8\n",
    "           0.285, 0.143, 0.302, 0.151,     # tau\n",
    "           0.124, 0.770,                   # a\n",
    "           0.805, 3.078, -2.120, 1]        # u0, b, w, k_action\n",
    "\n",
    "#          w1, w4                        w5, w7                           tau\n",
    "bounds = [(-1, 0) for _ in range(2)] + [(-2.5, -1) for _ in range(2)] + [(0.1, 0.5) for _ in range(4)] +\\\n",
    "         [(0.075, 0.2), (0.5, 1), (0, 2), (0, 4), (-4, 0), (0.3, 8)]\n",
    "#               a1         a2       u0      b       w       k_action\n",
    "\n",
    "n_iter = 150\n",
    "pbar = tqdm(total=n_iter)\n",
    "\n",
    "def callback(x, convergence):\n",
    "    print(f'params = {x}; convergence = {convergence}\\n')\n",
    "    with open('params.log', 'a') as f:\n",
    "        f.write(f'params = {x}; convergence = {convergence}\\n')\n",
    "    pbar.update(1)\n",
    "\n",
    "res = differential_evolution(Walker750.calc_reward, bounds, maxiter=n_iter, callback=callback,\n",
    "                             disp=True, x0=params0, updating='deferred', workers=9)\n",
    "pbar.close()\n",
    "\n",
    "# 16 - 45min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
